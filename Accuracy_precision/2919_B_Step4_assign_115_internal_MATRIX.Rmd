---
title: "Microchemistry discrimination"
author: "Neil"
date: "20 January 2017"
output: html_document
editor_options: 
  chunk_output_type: console
---
#setup
```{r setup, include=FALSE}
rm(list=ls())
# getwd tells us where R is looking
getwd()
#setwd tells R where to look
#setwd('/Volumes/PHD/R_script/Microchemistry/Dec2016')


setwd("E:/Otolith_chem_paper/Elemental_maps")
#library(devtools)
#install_github("jokergoo/ComplexHeatmap")

dat<- read.csv('chem2017_Tidy.csv')
#library(ComplexHeatmap)
library(AID)
library(vegan)
library(MASS)
library(corrplot)
library(fields)
require(randomForest)
library(PMCMR)
library(gamm4)
library(mvabund)
library(KernSmooth)
library(GISTools)
library(SDMTools)
library(maps)
library(mapdata)
library(RgoogleMaps)
library(PBSmapping)
library(plyr)
library(raster)
library(rgdal)
library(spatial.tools)
library(RColorBrewer)
library(rgeos)
library(rasterVis)
library(rgl)
library(gstat)
library(ipred)
library(sampling)
library(fitdistrplus)
library(Rfast)
library(sampSurf)


source("sdm_functions.R")

### summary data for methods
summary(dat)
levels(dat$ID)
names(dat)

dat<- subset(dat, dat$use=='y')
summary(dat$Area)
max(dat$Pit_no)
min(dat$Pit_no)
# subset for the time points we want
# and get the edge data


all1.15<- subset(dat, dat$sample_time ==1.15)
all1.15<- subset(all1.15, all1.15$Age =='1')

all1.15<- droplevels(all1.15)
length(unique(all1.15$ID))


#edge<- subset(all1.15, all1.15$Reverse_pit_no=='1')
#table(edge$Haul_id)
#sum(as.vector(table(edge$Haul_id)))
#table(edge$Sex)

names(all1.15)
summary(all1.15$pred_month)

# select Sept, Oct, Nov

int<- subset(all1.15,   all1.15$pred_month=='Sep' | all1.15$pred_month=='Oct' )
int<- droplevels(int)
str(int)
int$Mn_0<- as.numeric(as.character(int$Mn_0))

table(int$pred_month)
# there may be multiple samples from one otolith
table(int$ID)
sum(table(int$ID))
length(unique(int$ID))# these 2 lines will check that by trimming out months I'm not loosing data
unique(int$ID)
table(int$Sex)
set.seed(666)
s1 <- sampling::strata(int, stratanames="ID", size=rep(1, length(unique(int$ID))), method="srswr") 
int<-int[s1[,2],]

table(int$ID)
unique(int$ID)
table(int$ID)
head(int)
nrow(int)

####I looked at the mapped haul_id s and assigned each to a region
#probably want to remove the two south east IS ones 137 and 133 - also 126 might be odd too
int<- subset(int, int$Haul_id !='133')
int<- subset(int, int$Haul_id !='137')

 table(int$Haul_id)
# chem<- subset(chem, chem$HaulF !='133')
# chem<- subset(chem, chem$HaulF !='137')
# chem<- subset(chem, chem$HaulF !='118')
# chem<- subset(chem, chem$HaulF !='127')
# chem<- subset(chem, chem$HaulF !='126')

int<- droplevels(int)





table(int$Haul_id)
region<-as.factor(int$Haul_id)
# Use this code if I decide to turn this into regions again or pool any 2 hauls
# levels(region) <- c("Inshore",
#                     "Inshore", 
#                     "Clyde",
#                     "Inshore",
#                     "Inshore",
#                     "Inshore",
#                     "EIS",
#                     "Inshore",
#                     "EIS",
#                     "WIS")
int<-cbind(int, region)

table(int$Haul_id)
sum(as.vector(table(int$Haul_id)))

```

#Data sorting as per step2 (414)
```{r}
# Go through each element in turn, check for normality, growth relationship and correct
# no point doing them all might as well only do the ones included in the model.... Sr+ Mn


#Na
 
 # hist(int$Na)
 # shapiro.test(int$Na)  ## Normal 
 # qqnorm(int$Na); qqline(int$Na, col = 2)
 # 
 
#  
#  
# # growth relationship
#  plot(Na~Dist_to_pit, data=int)
#  lineNa<- lm(Na~Dist_to_pit, data=int) ##  Sig
#  summary(lineNa)
#  abline(lineNa)
#  
#   #NaCor<- lineNa$residuals
 #hist(NaCor)
 chem<- data.frame('ID'= int$ID)
 #chem<- data.frame('ID'= int$ID, 'Na'= int$Na)
# 
# 
# #Mg
# hist(ed4.14$Mg)
# shapiro.test(ed4.14$Mg)  ##Normal
# qqnorm(ed4.14$Mg); qqline(ed4.14$Mg, col = 2)
# 
# 
# plot(Mg~Dist_to_pit, data=ed4.14)
# lineMg<- lm(Mg~Dist_to_pit, data=ed4.14) ## non-Sig
# summary(lineMg)
# abline(lineMg)
# 
# chem<- cbind(chem, 'Mg'=int$Mg)
# 
# 
# #P
 #summary(int$P)

#hist(int$P)
#shapiro.test(int$P)  ##Normal - no need to transform
#qqnorm(int$P); qqline(int$P, col = 2)
 ## apply previous transformation



#chem<- cbind(chem, 'P'=int$P)

#Ba

 #summary(int$Ba)

#hist(int$Ba)
#shapiro.test(int$Ba)  
#qqnorm(int$Ba); qqline(int$Ba, col = 2)
 ## apply previous transformation
## apply previous transformation

#Baa<- ((int$Ba^-0.4)-1)/-0.4 # this follows the previous transformation applied
#hist(Baa)
#shapiro.test(Baa)  
#qqnorm(Baa); qqline(Baa, col = 2)


#chem<- cbind(chem, 'Ba'=int$Ba)
# 
# hist(ed4.14$Ba)
# shapiro.test(ed4.14$Ba)  ##Non-Normal
# qqnorm(ed4.14$Ba); qqline(ed4.14$Ba, col = 2)
# 
# #normalise
# Baout<- boxcoxnc(ed4.14$Ba)
# BaT<-Baout$tf.data
# shapiro.test(BaT)
# qqnorm(BaT); qqline(BaT, col = 2)   ##Normal
# hist(BaT)
# 
# 
# plot(BaT~Dist_to_pit, data=ed4.14)
# lineBaT<- lm(BaT~Dist_to_pit, data=ed4.14) ## Sig
# summary(lineBaT)
# abline(lineBaT)
# 
# # corect for length
# 
# BaCor<- lineBaT$residuals
# 
# hist(BaCor)
# shapiro.test(BaCor)  ##Normal
# qqnorm(BaCor); qqline(BaCor, col = 2)
# 
# chem<- cbind(chem, BaCor)

#Sr
summary(int$Sr)
hist(int$Sr)
shapiro.test(int$Sr)  ## not-Normal
shapiro.test(rnorm(50,5,2.5))
qqnorm(int$Sr); qqline(int$Sr, col = 2)

# 
# 
# plot(Sr~Dist_to_pit, data=int)
# lineSr<- lm(Sr~Dist_to_pit, data=int) ##  Sig
# summary(lineSr)
# abline(lineSr)
# 
# SrCor<- lineSr$residuals
# 
# hist(SrCor)
# shapiro.test(SrCor)  ## Normal
# qqnorm(SrCor); qqline(SrCor, col = 2)


chem<- cbind(chem, 'Sr'= int$Sr)

#Mn 0
summary(int$Mn)

hist(int$Mn_0+0.1)
#shapiro.test(int$Mn_0+1)  ##Non-Normal
#qqnorm(int$Mn_0+1); qqline(int$Mn_0+1, col = 2)

### apply previous transformation

#Mnn<- (((int$Mn_0+1)^-0.53)-1)/-0.53 # this follows the previous transformation applied
#hist(Mnn)
#shapiro.test(Mnn)  ## not Normal 
#qqnorm(Mnn); qqline(Mnn, col = 2)



chem<- cbind(chem, 'Mn'= int$Mn_0+0.1)


#Zn 
# summary(ed4.14$Zn)
# 
# hist(ed4.14$Zn)
# shapiro.test(ed4.14$Zn)  ##Non-Normal
# qqnorm(ed4.14$Zn); qqline(ed4.14$Zn, col = 2)
# 
# #normalise
# Znout<- boxcoxnc(ed4.14$Zn)
# ZnT<-Znout$tf.data
# shapiro.test(ZnT)
# qqnorm(ZnT); qqline(ZnT, col = 2)   ##not Normal
# hist(ZnT)
# 
# 
# plot(Zn~Dist_to_pit, data=ed4.14)
# lineZn<- lm(Zn~Dist_to_pit, data=ed4.14) ## not Sig
# summary(lineZn)
# abline(lineZn)
# 
# 
# chem<- cbind(chem, 'Zn'=ed4.14$Zn)
# 
# #Ni
# summary(ed4.14$Ni)
# 
# hist(ed4.14$Ni)
# shapiro.test(ed4.14$Ni)  ##Non-Normal
# qqnorm(ed4.14$Ni); qqline(ed4.14$Ni, col = 2)
# 
# #normalise
# Niout<- boxcoxnc(ed4.14$Ni)
# NiT<-Niout$tf.data
# shapiro.test(NiT)
# qqnorm(NiT); qqline(NiT, col = 2)   ## not - Normal
# hist(NiT)
# 
# 
# plot(Ni~Dist_to_pit, data=ed4.14)
# lineNi<- lm(Ni~Dist_to_pit, data=ed4.14) ## Sig
# summary(lineNi)
# abline(lineNi)
# 
# # corect for length
# 
# NiCor<- lineNi$residuals
# 
# hist(NiCor)
# shapiro.test(NiCor)  ##not Normal
# qqnorm(NiCor); qqline(NiCor, col = 2)
# 
# 
# chem<- cbind(chem, NiCor)
# 
# #Cu
# summary(ed4.14$Cu)
# 
# hist(ed4.14$Cu)
# shapiro.test(ed4.14$Cu)  ##Non-Normal
# qqnorm(ed4.14$Cu); qqline(ed4.14$Cu, col = 2)
# 
# #normalise
# Cuout<- boxcoxnc(ed4.14$Cu) 
# CuT<-Cuout$tf.data
# shapiro.test(CuT)
# qqnorm(CuT); qqline(CuT, col = 2)   ## Normal
# hist(CuT)
# 
# 
# plot(CuT~Dist_to_pit, data=ed4.14)
# lineCuT<- lm(CuT~Dist_to_pit, data=ed4.14) ## non Sig
# summary(lineCuT)
# abline(lineCuT)
# 
# 
# 
# chem<- cbind(chem, CuT)
# 

#Rb
# summary(int$Rb)
# 
# hist(int$Rb)
# shapiro.test(int$Rb)  ##Non-Normal
# qqnorm(int$Rb); qqline(int$Rb, col = 2)



#what distrobution
# hist(int$Rb)
# descdist(int$Rb, boot=500)
# f<-fitdistr(int$Rb, 'gamma')
# plotdist(int$Rb, distr='gamma', para=list(shape=4.2, rate=57.4))
# rate.est<- mean(int$Rb)/var(int$Rb)
# rate.est
# shape.est<- (mean(int$Rb)^2)/var(int$Rb)
# shape.est
# plotdist(int$Rb, distr='gamma', para=list(shape=shape.est, rate=rate.est))

#chem<- cbind(chem, 'Rb'=int$Rb)


#Cr_0
# summary(ed4.14$Cr)
# 
# hist(ed4.14$Cr)
# shapiro.test(ed4.14$Cr)  ##Non-Normal
# qqnorm(ed4.14$Cr); qqline(ed4.14$Cr, col = 2)
# 
# #normalise
# Crout<- boxcoxnc(ed4.14$Cr)   ##non Normal
# 
# 
# 
# plot(Cr~Dist_to_pit, data=ed4.14)
# lineCr<- lm(Cr~Dist_to_pit, data=ed4.14) ## non Sig
# summary(lineCr)
# abline(lineCr)
# 
# 
# chem<- cbind(chem, 'Cr'=ed4.14$Cr_0)

#Li &0
# summary(int$Li)
# 
# hist(int$Li_0+1)
# shapiro.test(int$Li_0)  ##Non-Normal
# qqnorm(int$Li_0); qqline(int$Li_0, col = 2)

#normalise
# Liout<- boxcoxnc(int$Li_0+1)   ##non Normal
# 
# 
# 
# plot(Li_0~Dist_to_pit, data=int)
# lineLi<- lm(Li_0~Dist_to_pit, data=int) ## Sig
# summary(lineLi)
# abline(lineLi)
# 
# LiCor<- lineLi$residuals
# 
# #what distrobution
# hist(int$Li_0)
# int$Li_0<- (int$Li_0+1)
# descdist(int$Li_0, boot=500)
# f<-fitdistr(int$Li_0, 'gamma')
# f
# plotdist(int$Li_0, distr='gamma', para=list(shape=4.2, rate=57.4))
# 
# rate.est<- mean(int$Li_0)/var(int$Li_0)
# rate.est
# shape.est<- (mean(int$Li_0)^2)/var(int$Li_0)
# shape.est
# plotdist(int$Li_0, distr='gamma', para=list(shape=shape.est, rate=rate.est))

#chem<- cbind(chem, 'Li'=int$Li_0+1)


#Al &0
# summary(ed4.14$Al)
# 
# hist(ed4.14$Al_0)
# shapiro.test(ed4.14$Al_0)  ##Non-Normal
# qqnorm(ed4.14$Al_0); qqline(ed4.14$Al_0, col = 2)
# 
# #normalise
# Alout<- boxcoxnc(ed4.14$Al_0+1) ## non Normal
# 
# 
# plot(Al_0~Dist_to_pit, data=ed4.14)
# lineAl<- lm(Al_0~Dist_to_pit, data=ed4.14) ## Sig
# summary(lineAl)
# abline(lineAl)
# 
# 
# chem<- cbind(chem, 'Al'=ed4.14$Al_0)

#Sc &0
# summary(int$Sc)
# 
# 
# hist(int$Sc_0+1)
# shapiro.test(int$Sc_0)  ##Non-Normal
# qqnorm(int$Sc_0); qqline(int$Sc_0, col = 2)
# 
# #normalise
# Scout<- boxcoxnc(int$Sc_0+1)   ## non Normal
# 
# 
# plot(Sc_0~Dist_to_pit, data=int)
# lineSc<- lm(Sc_0~Dist_to_pit, data=int) ## Sig
# summary(lineSc)
# abline(lineSc)
# 
# #what distrobution
# hist(int$Sc_0)
# int$Sc_0<- (int$Sc_0+1)
# descdist(int$Sc_0, boot=500)
# f<-fitdistr(int$Sc_0, 'gamma')
# f
# plotdist(int$Sc_0, distr='gamma', para=list(shape=3191, rate=1154))
# 
# rate.est<- mean(int$Sc_0)/var(int$Sc_0)
# rate.est
# shape.est<- (mean(int$Sc_0)^2)/var(int$Sc_0)
# shape.est
# plotdist(int$Sc_0, distr='gamma', demp=F, para=list(shape=shape.est, rate=rate.est))
# 
# 
# chem<- cbind(chem, 'Sc'=(int$Sc_0+1))

#Ti &0
# summary(ed4.14$Ti)
# 
# hist(ed4.14$Ti_0)
# shapiro.test(ed4.14$Ti_0)  ##Non-Normal
# qqnorm(ed4.14$Ti_0); qqline(ed4.14$Ti_0, col = 2)
# 
# #normalise
# Tiout<- boxcoxnc(ed4.14$Ti_0+1)##non Normal
# 
# 
# plot(Ti~Dist_to_pit, data=ed4.14)
# lineTi<- lm(Ti~Dist_to_pit, data=ed4.14) ## non Sig
# summary(lineTi)
# abline(lineTi)
# 
# 
# chem<- cbind(chem, 'Ti'=ed4.14$Ti_0)
# 
# #Y &0
# summary(ed4.14$Y)
# 
# 
# hist(ed4.14$Y_0)
# shapiro.test(ed4.14$Y_0)  ##Non-Normal
# qqnorm(ed4.14$Y_0); qqline(ed4.14$Y_0, col = 2)
# 
# #normalise
# Yout<- boxcoxnc(ed4.14$Y_0+1) ## non Normal
# 
# plot(Y_0~Dist_to_pit, data=ed4.14)
# lineY<- lm(Y_0~Dist_to_pit, data=ed4.14) ## non Sig
# summary(lineY)
# abline(lineY)
# 
# 
# chem<- cbind(chem, 'Y'=ed4.14$Y)
# 
# #Pb &0
# summary(ed4.14$Pb)
# 
# hist(ed4.14$Pb_0)
# shapiro.test(ed4.14$Pb_0)  ##Non-Normal
# qqnorm(ed4.14$Pb_0); qqline(ed4.14$Pb_0, col = 2)
# 
# #normalise
# Pbout<- boxcoxnc(ed4.14$Pb_0+1) ## non Normal
# 
# 
# plot(Pb_0~Dist_to_pit, data=ed4.14)
# linePb<- lm(Pb_0~Dist_to_pit, data=ed4.14) ## Sig
# summary(linePb)
# abline(linePb)
# 
# 
# chem<- cbind(chem, 'Pb'=ed4.14$Pb)
# 
# head(chem)
# summary(chem)
# str(chem)
# names(ed4.14)

# remove the outlier from previously
#chem<- chem[-57,]
#ed4.14<- ed4.14[-57,]

# bind some other useful stuff
chem<- cbind(chem, 'Area'= int$Area, 'Haul_id'= int$Haul_id, 'radius' = int$Dist_to_pit, 'long'= int$Mid_long, 'lat'= int$Mid_lat, 'HaulF'= as.factor(int$Haul_id), 'region'=as.factor(int$region))

table(chem$Haul_id)

par(mfrow=c(1,1))

```





# set spatial extent and pull in maps
```{r}
## spatial extent etc set-up
# 
full.ext<- extent(c(-10, -2, 52, 60))
###coord system to assign
WGS84<- '+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0'
#### projection
mrc <- '+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null +wktext +no_defs'
bathT<- raster('F:/R_script/SDM/full_area_time/layers_output/bath.grd')
base<- readOGR(dsn='F:/R_script/SDM', layer="full")

land<- readOGR(dsn= "F:/R_script/SDM/my_layers_collection", layer ='Britain_Proj_Dist')
land<- spTransform(land, CRS(WGS84))
land<- crop(land, full.ext)
base<- crop(base, full.ext)


landT<- spTransform(land, CRS(mrc))
baseT<- spTransform(base, CRS(mrc))
bathT<- crop(bathT, landT)# crop this here as it has already been transformed
```


# pull in surfaces and er
```{r}

# smoothed rasters
#normal
Na<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelNa_414.gri')
Na.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelNa_414.gri')

Mg<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelMg_414.gri')
Mg.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelMg_414.gri')

P<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelP_414.gri')
P.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelP_414.gri')

Ba<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelBa_414.gri')
Ba.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelBa_414.gri')

Sr<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelSr_414.gri')
Sr.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelSr_414.gri')

Mn<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelMn_414.gri')
Mn.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelMn_414.gri')

Zn<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelZn_414.gri')
Zn.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelZn_414.gri')

Rb<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelRb_414.gri')
Rb.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelRb_414.gri')

Li<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelLi_414.gri')
Li.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelLi_414.gri')

Sc<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/modelSc_414.gri')
Sc.er<- raster('E:/R_script/Microchemistry/elemental_maps/elem_layers/er_modelSc_414.gri')


```

#Plot hauls
```{r}

full.ext<- extent(c(-10, -2, 52, 60))


sea.spdf<- readOGR(dsn="E:/R_script/basic_maps", layer="basic_sea")
depth.sldf<- readOGR(dsn="E:/R_script/basic_maps", layer="depth_area")

land.tmp<- readOGR(dsn="E:/R_script/basic_maps", layer="Britain_Proj_Dist")
land.tmp <- spTransform(land.tmp, CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")) ### re project land
land.spdf <- crop(land.tmp, full.ext) ## crop land down to the correct extent


#### initially produce a map of everywhere and all time points
## bind coords into sigle object
coords.tmp<- cbind(int$Mid_long, int$Mid_lat)
## create spdf object
samples.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(int),
                                  proj4string = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))


#### subset depth for 200m line
twohun.sldf <- subset(depth.sldf, depth.sldf$ELEVATION == 200)
onehun.sldf<- subset(depth.sldf, depth.sldf$ELEVATION == 100)


#par(mar = c(4,1,1,1))


summary(land.spdf)


### plot land and sea####

plot(land.spdf, add = F, col = 'cornsilk', border = 'cornsilk')
plot(sea.spdf, add=T, col = 'cornflower blue')
## axes - note this needs changed on mac for degree symbol
axis(1, at = c(-1:-10),labels = parse(text = paste(c(1:10), "*degree~W", sep = "")), cex.axis = 1.5, pos = 52, tck = -0.015,padj=0.2)
axis(2, at = seq(52,60, by= 0.5), label = F,pos = -10, tck = -0.015)
axis(2, at = c(52:60), labels = parse(text = paste(c(52:60), "*degree ~ N", sep = "")),tick = F, pos = -10, las = 1, cex.axis=1.5, hadj=1)
axis(3, labels = F, pos = 59.7, at = c(-1:-10), lwd.ticks=0)
axis(4, labels = F, pos = -1, at = seq(52,59.5, by= 0.5), lwd.ticks=0)

## bathemetry
plot(onehun.sldf,add=T, col = ' lightskyblue3')
plot(twohun.sldf,add =T, col = 'lightskyblue4')
rect(-9.8, 55.7, -8.8, 56.3, col = 'cornflowerblue', border = NA )
rect(-9.6, 54.4, -8.8, 55.08, col = 'cornflowerblue', border = NA)
text(-9.2,56, labels= '200m', col ='lightskyblue4', cex = 0.8, srt = 81)
text(-9.35,54.8, labels= '100m', col ='lightskyblue3', cex = 0.8, srt = 65)

## country names
text(-3.6, 57, labels = 'Scotland', srt=40)
text(-1.8, 54, labels = 'England', srt=50)
text(-6.5, 54.7, labels = 'N. Ireland', srt=-54)
text(-7.5, 53, labels = 'Eire')
text(-3.4, 53, labels = 'Wales')


str(int$region)
### add sampling points
text(samples.spdf, labels=int$Haul_id)
#plot(samples.spdf, add =T, cex = 2.5, pch= c(15,17,19,2,3)[as.numeric(int$region)], lwd=2)

#legend(-2.75, 53.1,legend =levels(int$region),
  #     pch= c(15,17,19,2,3), cex = 1, box.col = 'black', bg = 'cornsilk', horiz = F)



north.arrow(xb=-9.5, yb=59, len=0.08, lab="N")

table(int$Haul_id)


```


#LL assignment by Haul

##117 N Minch
```{r}


summary(chem$region)
chem117<- subset(chem, chem$region =='117')

chem117<- droplevels(chem117)
nrow(chem117)
## log likelihood function 
n=mean(table(chem117$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem117) # ~20
samps= 20 

for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem117[sample(nrow(chem117), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('117', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
#din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig117<- llall#/j
plot(orig117, add=T)
plot(landT)


#########################################################
#blues<- colorRampPalette(brewer.pal(9,'Blues'), alpha=T)
#greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
temp<- c('#FFFFFF',brewer.pal(9,'YlOrRd')[2:9])
temp
temp<- colorRampPalette(temp)



##Temp cols
display.brewer.all()

#area.shades<- brewer.pal(9,'Set1')
#spec<- brewer.pal(11,'Spectral')
#spec<-colorRampPalette(rev(brewer.pal(11,'Spectral')))
#dave.heat<- colorRampPalette(rev(brewer.pal(9,'Blues')[4:9]))

point117<- SpatialPoints(cbind(chem117$long, chem117$lat), CRS(WGS84))
point117T<- spTransform(point117, CRS(mrc))

image(orig117, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig117, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey88')
plot(point117T, add=T, pch=19, col='black', cex=2)


plot(orig117)
(1121547 -319754.9)/1000
(8408038-6787878)/1000

```

##118 West offshore
```{r}


summary(chem$region)
chem118<- subset(chem, chem$region =='118')

mid= cbind(x=-722018.2, y=7704320) # mid inshore coords

chem118<- droplevels(chem118)


## log likelihood function 
n=mean(table(chem118$Haul_id))


# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }

   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er
 
   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
  
   Sr.big<-Sr
   Srer.big<-Sr.er
 
   Mn.big<-Mn
   Mner.big<-Mn.er
 
   Zn.big<-Zn
   Zner.big<-Zn.er
 
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
 
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem118) # ~20
samps= 20
for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem118[sample(nrow(chem118), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
    # optimal sets: Cl:  Rb, Sc
    #               EIS: Sr, Rb
    #               WIS: Mg, Sr, Rb, Cu - not great though
    #               Offshore: Na Rb Sc
    #               Inshore:Na Mg Cu Rb
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('118', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 

thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig118<- llall#/j
plot(orig118, add=T)
plot(landT)

#temp<- c(brewer.pal(9,'Reds')[1],brewer.pal(9,'YlOrRd')[2:9])
#temp
#temp<- colorRampPalette(temp)



##Temp cols
#display.brewer.all()

#area.shades<- brewer.pal(9,'Set1')
#spec<- brewer.pal(11,'Spectral')
#spec<-colorRampPalette(rev(brewer.pal(11,'Spectral')))
#dave.heat<- colorRampPalette(rev(brewer.pal(9,'Blues')[4:9]))

point118<- SpatialPoints(cbind(chem118$long, chem118$lat), CRS(WGS84))
point118T<- spTransform(point118, CRS(mrc))

image(orig118, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig118, col = temp(1000), zlim= c(0,nrow(chem118)), add=T)
plot(landT, add =T, col = 'grey88')
plot(point118T, add=T, pch=19, col='black', cex=2)



```


##121 Clyde
```{r}

summary(chem$region)
chem121<- subset(chem, chem$region =='121')

chem121<- droplevels(chem121)
nrow(chem121)
## log likelihood function 
n=mean(table(chem121$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem121) # ~20
samps= 20
for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem121[sample(nrow(chem121), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('121', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig121<- llall#/j
plot(orig121, add=T)
plot(landT)

blues<- colorRampPalette(brewer.pal(9,'Blues'), alpha=T)
greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
reds<- colorRampPalette(brewer.pal(9,'Reds'), alpha=T)

point121<- SpatialPoints(cbind(chem121$long, chem121$lat), CRS(WGS84))
point121T<- spTransform(point121, CRS(mrc))

image(orig121, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig121, col = temp(1000), zlim= c(0,nrow(chem121)), add=T)
plot(landT, add =T, col = 'grey88')
plot(point121T, add=T, pch=19, col='black', cex=2)


```

##122 Jura
```{r}

summary(chem$region)
chem122<- subset(chem, chem$region =='122')

chem122<- droplevels(chem122)
nrow(chem122)
## log likelihood function 
n=mean(table(chem122$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem122) # ~20
samps= 20
for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem122[sample(nrow(chem122), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('122', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig122<- llall#/j
plot(orig122, add=T)
plot(landT)

blues<- colorRampPalette(brewer.pal(9,'Blues'), alpha=T)
greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
reds<- colorRampPalette(brewer.pal(9,'Reds'), alpha=T)

point122<- SpatialPoints(cbind(chem122$long, chem122$lat), CRS(WGS84))
point122T<- spTransform(point122, CRS(mrc))


image(orig122, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig122, col = temp(1000), zlim= c(0,nrow(chem122)), add=T)
plot(landT, add =T, col = 'grey88')
plot(point122T, add=T, pch=19, col='black', cex=2)

```

##123 S Minch
```{r}

summary(chem$region)
chem123<- subset(chem, chem$region =='123')

chem123<- droplevels(chem123)
nrow(chem123)
## log likelihood function 
n=mean(table(chem123$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem123) # ~20
samps= 20
for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem123[sample(nrow(chem123), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('123', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig123<- llall#/j
plot(orig123, add=T)
plot(landT)

bluesG<- colorRampPalette(brewer.pal(9,'BuGn'), alpha=T)
greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
reds<- colorRampPalette(brewer.pal(9,'Reds'), alpha=T)

point123<- SpatialPoints(cbind(chem123$long, chem123$lat), CRS(WGS84))
point123T<- spTransform(point123, CRS(mrc))

image(orig123, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig123, col = temp(1000), zlim= c(0,nrow(chem123)), add=T)
plot(landT, add =T, col = 'grey88')
plot(point123T, add=T, pch=19, col='black', cex=2)


```

##124 Offshore
```{r}

summary(chem$region)
chem124<- subset(chem, chem$region =='124')

chem124<- droplevels(chem124)
nrow(chem124)
## log likelihood function 
n=mean(table(chem124$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem124) # ~20
samps= 20
for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem124[sample(nrow(chem124), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('124', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig124<- llall#/j
plot(orig124, add=T)
plot(landT)

blues<- colorRampPalette(brewer.pal(9,'Blues'), alpha=T)
greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
Yreds<- colorRampPalette(brewer.pal(9,'YlOrRd'), alpha=T)

point124<- SpatialPoints(cbind(chem124$long, chem124$lat), CRS(WGS84))
point124T<- spTransform(point124, CRS(mrc))

image(orig124, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig124, col = temp(1000), zlim= c(0,nrow(chem124)), add=T)
plot(landT, add =T, col = 'grey88')
plot(point124T, add=T, pch=19, col='black', cex=2)

```

##126 E IS
```{r}

summary(chem$region)
chem126<- subset(chem, chem$region =='126')

chem126<- droplevels(chem126)
nrow(chem126)
## log likelihood function 
n=mean(table(chem126$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE

#samps= nrow(chem126) # ~20
samps= 20

for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem126[sample(nrow(chem126), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('126', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig126<- llall#/j
plot(orig126, add=T)
plot(landT)

purps<- colorRampPalette(brewer.pal(9,'Purples'), alpha=T)
greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
Yreds<- colorRampPalette(brewer.pal(9,'YlOrRd'), alpha=T)

point126<- SpatialPoints(cbind(chem126$long, chem126$lat), CRS(WGS84))
point126T<- spTransform(point126, CRS(mrc))

image(orig126, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig126, col = temp(1000), zlim= c(0,nrow(chem126)), add=T)
plot(landT, add =T, col = 'grey88')
plot(point126T, add=T, pch=19, col='black', cex=2)

```


##127 N N Minch
```{r}

summary(chem$region)
chem127<- subset(chem, chem$region =='127')

chem127<- droplevels(chem127)
nrow(chem127)
## log likelihood function 
n=mean(table(chem127$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem127) # ~20
samps= 20

for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem127[sample(nrow(chem127), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('127', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig127<- llall#/j
plot(orig127, add=T)
plot(landT)

blues<- colorRampPalette(brewer.pal(9,'Blues'), alpha=T)
greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
Yreds<- colorRampPalette(brewer.pal(9,'YlOrRd'), alpha=T)

point127<- SpatialPoints(cbind(chem127$long, chem127$lat), CRS(WGS84))
point127T<- spTransform(point127, CRS(mrc))

image(orig127, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig127, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey88')
plot(point127T, add=T, pch=19, col='black', cex=2)

```

##135 NEIS
```{r}

summary(chem$region)
chem135<- subset(chem, chem$region =='135')

chem135<- droplevels(chem135)
nrow(chem135)
## log likelihood function 
n=mean(table(chem135$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem135) # ~20
samps= 20

for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem135[sample(nrow(chem135), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('135', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig135<- llall#/j
plot(orig135, add=T)
plot(landT)

blues<- colorRampPalette(brewer.pal(9,'Blues'), alpha=T)
greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
OrReds<- colorRampPalette(brewer.pal(9,'OrRd'), alpha=T)

point135<- SpatialPoints(cbind(chem135$long, chem135$lat), CRS(WGS84))
point135T<- spTransform(point135, CRS(mrc))

image(orig135, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig135, col = temp(1000), zlim= c(0,nrow(chem135)), add=T)
plot(landT, add =T, col = 'grey88')
plot(point135T, add=T, pch=19, col='black', cex=2)


```


##136 WIS
```{r}

summary(chem$region)
chem136<- subset(chem, chem$region =='136')

chem136<- droplevels(chem136)
nrow(chem136)
## log likelihood function 
n=mean(table(chem136$Haul_id))



# #Set 1 not -pooled so in the function we change SE from the raster to var to work out rate and shape
 ll.norm <- function(parameters, thedata)
   {
   ll <- (dnorm(thedata, mean=parameters[1], sd=(parameters[2]*sqrt(n)), log=TRUE))
  return(ll)
 }
# 
# ## log likelihood function for gamma distribution elements
 ll.gam <- function(parameters, thedata)
   {
   ll <- (dgamma(thedata, rate=parameters[1]/((parameters[2]^2)*n), shape=(parameters[1]^2)/((parameters[2]^2)*n), log=TRUE))
   return(ll)
 }


   Na.big<-Na
   Naer.big<-Na.er
   
   Mg.big<-Mg
  Mger.big<-Mg.er

   P.big<-P
   Per.big<- P.er
  
   Ba.big<-Ba
  Baer.big<-Ba.er
 
   Sr.big<-Sr
   Srer.big<-Sr.er

   Mn.big<-Mn
   Mner.big<-Mn.er

   Zn.big<-Zn
   Zner.big<-Zn.er
  
   Rb.big<-Rb
   Rber.big<-Rb.er
  
   Li.big<-Rb
   Lier.big<-Li.er
  
stk<-stack(Na.big, Naer.big, Mg.big, Mger.big, P.big, Per.big,  Ba.big, Baer.big, Sr.big, Srer.big,  Mn.big, Mner.big, Zn.big, Zner.big, Rb.big, Rber.big, Li.big, Lier.big) # make a raster stack form the above

param<- as.data.frame(stk, xy=TRUE)# change the above raster back to a dataframe to compute ll

names(param)[3:20]<- c('meanNa', 'sdNa', 'meanMg', 'sdMg','meanP', 'sdP', 'meanBa', 'sdBa', 'meanSr', 'sdSr', 'meanMn', 'sdMn', 'meanZn', 'sdZn', 'meanRb', 'sdRb', 'meanLi', 'sdLi')
param<- cbind(param, ll=NA) # add the log likelyhood column
head(param)

d=NA #vector to store geographic dists in
din=NA # vector to store geographic dists for inshore in
dll=NA # vector to store vertical distances in
first.run<- TRUE
#samps= nrow(chem136) # ~20

samps= 20
for (j in 1:samps)
{
  
## pull a sample row from data
samp<- chem136[sample(nrow(chem136), 1, replace =FALSE), ]
answer= samp$Area # save the answer row for later

# make sample into an sp object and project
coords.tmp<- cbind(samp$long, samp$lat)
## create spdf object
samp.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(samp),
                                   proj4string = CRS(WGS84))
samp.spdfT<- spTransform(samp.spdf, CRS(mrc))


# a loop to estimate liklihood of the data given the parameters and add it to the ll column of param

  for(i in 1:nrow(param))
  #remove the elements not being used
 
  {
     #Na.param <- ll.norm(parameters=c(param$meanNa[i],param$sdNa[i]), thedata=samp$Na)
    # Mg.param <- ll.norm(parameters=c(param$meanMg[i],param$sdMg[i]), thedata=samp$Mg)
     #P.param <- ll.norm(parameters=c(param$meanP[i],param$sdP[i]), thedata=samp$P)
     #Ba.param <- ll.gam(parameters=c(param$meanBa[i],param$sdBa[i]), thedata=samp$Ba)
     Sr.param <- ll.norm(parameters=c(param$meanSr[i],param$sdSr[i]), thedata=samp$Sr)
     Mn.param <- ll.gam(parameters=c(param$meanMn[i],param$sdMn[i]), thedata=samp$Mn)
     #Zn.param <- ll.gam(parameters=c(param$meanZn[i],param$sdZn[i]), thedata=samp$Zn)
     #Rb.param <- ll.gam(parameters=c(param$meanRb[i],param$sdRb[i]), thedata=samp$Rb)
     #Li.param <- ll.gam(parameters=c(param$meanLi[i],param$sdLi[i]), thedata=samp$Li)
  
   
    
    param[i,21]<- (#Na.param +
                   #Mg.param +
                  # P.param +
                     # Ba.param+
                      Sr.param +
                      Mn.param 
                      #Cu.param +
                      #Rb.param 
                     #Li.param
                     
                     )
  }



##turn ll into sp object
coords.tmp<- cbind(param$x, param$y)
## create spdf object
ll.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(param),
                                   proj4string = CRS(mrc))

#then rasterise and the ll sp object
ll.r<- raster(Na.big)
ll.r<- rasterize(ll.spdf, ll.r, field = 'll', fun = mean)

#plot the likelihood surface
image(ll.r, main=paste('136', j, sep=" "))
points(subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE)),cex=6) # add circle for highest point

##save likelyhood surfaces into a folder
#writeRaster(ll.r, file=paste('E:/R_script/Microchemistry/elemental_maps/ass_surf/clLL', j, sep=""), format = 'raster', overwrite=T)


corr<- subset(ll.spdf, ll.spdf$ll==max(ll.spdf$ll,na.rm = TRUE))
corr.r<- rasterize(corr, ll.r, field='meanNa', fun=mean)
samp.r<- rasterize(samp.spdfT, ll.r, field='Sr', fun=mean)

#image(corr.r, add=T, col ='black') #plot the guess
image(samp.r, add=T, col = 'blue') # plot the truth


d[j]<- dist(rbind(corr@coords,samp.spdfT@coords), method = "euclidean")
## for inshore area use
din[j]<- dist(rbind(corr@coords,mid), method = "euclidean")
dll[j]<- (maxValue(mask(ll.r, corr.r)) - maxValue(mask(ll.r, samp.r)))^2

llScale<- ll.r
 
## write in a function to trim out all unlikey cells ie leaves all the likely ones from the % area defined previously from precision vs Accuracy 
#thresh


thresh<- unname(quantile(llScale, an.rm=TRUE, probs=1-0.08)) #this threshold value is the one from the ROC curve which maximises accuract and precision


  fun1<- function(x) {ifelse(x<thresh, 0, 1)}
    
    lltop<- calc(llScale, fun=fun1) ## apply the function
plot(lltop, col=c('#9ecae1','#3182bd'))
plot(landT, add=T, col='bisque')

answer

 if (first.run)
  {
    llall <- lltop
    first.run <- FALSE
  } else {
    llall <- llall+lltop
  }

}


orig136<- llall#/j
plot(orig136, add=T)
plot(landT)

blues<- colorRampPalette(brewer.pal(9,'Blues'), alpha=T)
greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
greys<- colorRampPalette(brewer.pal(9,'Greys'), alpha=T)

point136<- SpatialPoints(cbind(chem136$long, chem136$lat), CRS(WGS84))
point136T<- spTransform(point136, CRS(mrc))

image(orig136, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA)
image(orig136, col = temp(1000), zlim= c(0,nrow(chem136)), add=T)
plot(landT, add =T, col = 'grey88')
plot(point136T, add=T, pch=19, col='black', cex=2)

```

# Save plots
```{r}
# 
# writeRaster(orig117, filename="Nminch117.grd", overwrite=TRUE)
# writeRaster(orig118, filename="Woff118.grd", overwrite=TRUE)
# writeRaster(orig121, filename="Clyde121.grd", overwrite=TRUE)
# writeRaster(orig122, filename="Jura122.grd", overwrite=TRUE)
# writeRaster(orig123, filename="Sminch123.grd", overwrite=TRUE)
# writeRaster(orig124, filename="Off124.grd", overwrite=TRUE)
# writeRaster(orig126, filename="EIS126.grd", overwrite=TRUE)
# writeRaster(orig127, filename="NNminch127.grd", overwrite=TRUE)
# writeRaster(orig135, filename="NEIS135.grd", overwrite=TRUE)
# writeRaster(orig136, filename="WIS136.grd", overwrite=TRUE)



```


#read in rasters
```{r}

NM<- raster("Nminch117.grd")/20
Woff<- raster("Woff118.grd")/20
Cl<- raster("Clyde121.grd")/20
Jur<- raster("Jura122.grd")/19
SM<- raster("Sminch123.grd")/20
Off<- raster("Off124.grd")/20
EIS<- raster("EIS126.grd")/17
NNM<- raster("NNminch127.grd")/16
NEIS<- raster("NEIS135.grd")/19
WIS<- raster("WIS136.grd")/17


```

#Acrual matrix
```{r}

##make the circles
plot(NNM)
#plot(NEIS)


rad=130*1000
c.NNM<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point127T@coords[[1,1]], y = point127T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

plot(c.NNM, add=T)

c.Off<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point124T@coords[[1,1]], y = point124T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.Off, add=T)

c.NM<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point117T@coords[[1,1]], y = point117T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.NM, add=T)

c.Woff<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point118T@coords[[1,1]], y = point118T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.Woff, add=T)


c.SM<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point123T@coords[[1,1]], y = point123T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.SM, add=T)


c.Jur<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point122T@coords[[1,1]], y = point122T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.Jur, add=T)


c.Cl<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point121T@coords[[1,1]], y = point121T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.Cl, add=T)


c.NEIS<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point135T@coords[[1,1]], y = point135T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.NEIS, add=T)


c.WIS<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point136T@coords[[1,1]], y = point136T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.WIS, add=T)


c.EIS<- spCircle(rad,
         spUnits = CRS(mrc),
         centerPoint = c(x = point126T@coords[[1,1]], y = point126T@coords[[1,2]]),
         nptsPerimeter = 100,
         spID = paste("circle", .StemEnv$randomID(), sep = ":"))$spCircle

#plot(c.EIS, add=T)

## extract the mean for the circle
mean.cont<- data.frame('NNM'= NA, 'Off'= NA, 'NM'=NA, 'Woff'=NA, 'SM'=NA, 'Jur'=NA, 'Cl'=NA, 'NEIS'=NA, 'WIS'=NA, 'EIS'=NA)

mean.cont[1,1]<- extract(NNM, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,1]<- extract(NNM, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,1]<- extract(NNM, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,1]<- extract(NNM, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,1]<- extract(NNM, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,1]<- extract(NNM, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,1]<- extract(NNM, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,1]<- extract(NNM, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,1]<- extract(NNM, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,1]<- extract(NNM, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,2]<- extract(Off, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,2]<- extract(Off, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,2]<- extract(Off, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,2]<- extract(Off, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,2]<- extract(Off, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,2]<- extract(Off, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,2]<- extract(Off, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,2]<- extract(Off, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,2]<- extract(Off, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,2]<- extract(Off, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,3]<- extract(NM, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,3]<- extract(NM, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,3]<- extract(NM, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,3]<- extract(NM, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,3]<- extract(NM, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,3]<- extract(NM, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,3]<- extract(NM, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,3]<- extract(NM, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,3]<- extract(NM, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,3]<- extract(NM, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,4]<- extract(Woff, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,4]<- extract(Woff, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,4]<- extract(Woff, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,4]<- extract(Woff, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,4]<- extract(Woff, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,4]<- extract(Woff, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,4]<- extract(Woff, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,4]<- extract(Woff, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,4]<- extract(Woff, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,4]<- extract(Woff, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,5]<- extract(SM, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,5]<- extract(SM, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,5]<- extract(SM, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,5]<- extract(SM, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,5]<- extract(SM, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,5]<- extract(SM, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,5]<- extract(SM, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,5]<- extract(SM, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,5]<- extract(SM, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,5]<- extract(SM, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,6]<- extract(Jur, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,6]<- extract(Jur, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,6]<- extract(Jur, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,6]<- extract(Jur, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,6]<- extract(Jur, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,6]<- extract(Jur, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,6]<- extract(Jur, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,6]<- extract(Jur, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,6]<- extract(Jur, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,6]<- extract(Jur, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,7]<- extract(Cl, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,7]<- extract(Cl, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,7]<- extract(Cl, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,7]<- extract(Cl, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,7]<- extract(Cl, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,7]<- extract(Cl, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,7]<- extract(Cl, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,7]<- extract(Cl, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,7]<- extract(Cl, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,7]<- extract(Cl, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,8]<- extract(NEIS, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,8]<- extract(NEIS, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,8]<- extract(NEIS, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,8]<- extract(NEIS, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,8]<- extract(NEIS, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,8]<- extract(NEIS, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,8]<- extract(NEIS, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,8]<- extract(NEIS, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,8]<- extract(NEIS, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,8]<- extract(NEIS, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,9]<- extract(WIS, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,9]<- extract(WIS, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,9]<- extract(WIS, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,9]<- extract(WIS, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,9]<- extract(WIS, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,9]<- extract(WIS, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,9]<- extract(WIS, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,9]<- extract(WIS, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,9]<- extract(WIS, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,9]<- extract(WIS, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)

mean.cont[1,10]<- extract(EIS, c.NNM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[2,10]<- extract(EIS, c.Off, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[3,10]<- extract(EIS, c.NM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[4,10]<- extract(EIS, c.Woff, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[5,10]<- extract(EIS, c.SM, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[6,10]<- extract(EIS, c.Jur, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[7,10]<- extract(EIS, c.Cl, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[8,10]<- extract(EIS, c.NEIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[9,10]<- extract(EIS, c.WIS, method='bilinear', fun=mean,  na.rm=TRUE)
mean.cont[10,10]<- extract(EIS, c.EIS, method='bilinear', fun=mean,  na.rm=TRUE)


head(mean.cont)

mean.cont.m<- as.matrix(mean.cont)
apply(mean.cont.m, MARGIN = 1, FUN= sum)

image(mean.cont.m, xaxt='n', yaxt='n',col=blues(1000))
axis(3, at=c( 0.0, 0.11, 0.22, 0.33, 0.44, 0.55, 0.66, 0.77, 0.88, 1), labels=c("NNM", "Off", 'NM', 'Woff', 'SM', 'Jur', 'Cl', 'NEIS', 'WIS', 'EIS'))
axis(2, at=rev(c( 0.0, 0.11, 0.22, 0.33, 0.44, 0.55, 0.66, 0.77, 0.88, 1)), labels=c("NNM", "Off", 'NM', 'Woff', 'SM', 'Jur', 'Cl', 'NEIS', 'WIS', 'EIS'), las=2)
#axis(2, at = seq(0,1, length.out= 17), label = F,pos = -0.06, tck = -0.015)

#axis(2, at = seq(0,1, length.out= 9), labels = parse(text = paste(c(52:60), "*degree ~ N", sep = "")),tick = F, pos = -0.06, las = 1, cex.axis=1.5, hadj=1)

marg<- matrix(nrow=9, ncol=10)
 marg1<-  apply(mean.cont.m, MARGIN = 1, FUN= sum)
marg.test<- rbind( marg1, marg)

image(t(marg.test), col=blues(1000), ylim=c(0,0.5), xaxt='n', yaxt='n', axes=FALSE)
axis(1, at=c( 0.0, 0.11, 0.22, 0.33, 0.44, 0.55, 0.66, 0.77, 0.88, 1), labels=c("NNM", "Off", 'NM', 'Woff', 'SM', 'Jur', 'Cl', 'NEIS', 'WIS', 'EIS'))
#axis(2, at=rev(c( 0.0, 0.11, 0.22, 0.33, 0.44, 0.55, 0.66, 0.77, 0.88, 1)), labels=c("NNM", "Off", 'NM', 'Woff', 'SM', 'Jur', 'Cl', 'NEIS', 'WIS', 'EIS'), las=2)


marg<- matrix(nrow=10, ncol=9)
 marg1<-  apply(mean.cont.m, MARGIN = 2, FUN= sum)
marg.test<- cbind( marg1, marg)

image(t(marg.test), col=blues(1000), xaxt='n', yaxt='n', axes=FALSE)
axis(2, at=rev(c( 0.0, 0.11, 0.22, 0.33, 0.44, 0.55, 0.66, 0.77, 0.88, 1)), labels=c("NNM", "Off", 'NM', 'Woff', 'SM', 'Jur', 'Cl', 'NEIS', 'WIS', 'EIS'), las=2)


```


```{r }
plot(NNM)
plot(point127T, add=T, pch=19, col='black', cex=2)
 

plot(NNM)
plot(c.NNM$spCircle, add=TRUE)



# r1<- NNM
# stepsize = (r1@extent@ymax - r1@extent@ymin) / r1@nrows
# yvals = seq(r1@extent@ymax - stepsize / 2, r1@extent@ymin, -stepsize)
# xvals1 = rowMeans(as.matrix(r1), na.rm=TRUE)
# 
# plot(xvals1, yvals, type='l')
# point127T@coords[1,]
# abline(h=point127T@coords[1,2])
# 
# 
# 
# plot(Off)
# plot(point124T, add=T, pch=19, col='black', cex=2)
# 
# r2<- Off
# stepsize = (r2@extent@ymax - r2@extent@ymin) / r2@nrows
# yvals = seq(r2@extent@ymax - stepsize / 2, r2@extent@ymin, -stepsize)
# xvals2 = rowMeans(as.matrix(r2), na.rm=TRUE)
# 
# plot(xvals2, yvals, type='l')
# point124T@coords[1,2]
# abline(h=point124T@coords[1,2])
# 
# 
# 
# 
# 
# plot(NM)
# plot(point117T, add=T, pch=19, col='black', cex=2)
# 
# r3<- NM
# stepsize = (r3@extent@ymax - r3@extent@ymin) / r3@nrows
# yvals = seq(r3@extent@ymax - stepsize / 2, r3@extent@ymin, -stepsize)
# xvals3 = rowMeans(as.matrix(r3), na.rm=TRUE)
# 
# plot(xvals3, yvals, type='l')
# point117T@coords[1,2]
# abline(h=point117T@coords[1,2])
# 
# 
# 
# 
# 
# plot(Woff)
# plot(point118T, add=T, pch=19, col='black', cex=2)
# 
# r4<- Woff
# stepsize = (r4@extent@ymax - r4@extent@ymin) / r4@nrows
# yvals = seq(r4@extent@ymax - stepsize / 2, r4@extent@ymin, -stepsize)
# xvals4 = rowMeans(as.matrix(r4), na.rm=TRUE)
# 
# plot(xvals4, yvals, type='l')
# point118T@coords[1,2]
# abline(h=point118T@coords[1,2])
# 
# 
# 
# plot(SM)
# plot(point123T, add=T, pch=19, col='black', cex=2)
# 
# r5<- SM
# stepsize = (r5@extent@ymax - r5@extent@ymin) / r5@nrows
# yvals = seq(r5@extent@ymax - stepsize / 2, r5@extent@ymin, -stepsize)
# xvals5 = rowMeans(as.matrix(r5), na.rm=TRUE)
# 
# plot(xvals5, yvals, type='l')
# point123T@coords[1,2]
# abline(h=point121T@coords[1,2])
# 
# 
# 
# 
# plot(Jur)
# plot(point122T, add=T, pch=19, col='black', cex=2)
# 
# r6<- Jur
# stepsize = (r6@extent@ymax - r6@extent@ymin) / r6@nrows
# yvals = seq(r6@extent@ymax - stepsize / 2, r6@extent@ymin, -stepsize)
# xvals6 = rowMeans(as.matrix(r6), na.rm=TRUE)
# 
# plot(xvals6, yvals, type='l')
# point122T@coords[1,2]
# abline(h=point122T@coords[1,2])
# 
# 
# 
# 
# plot(Cl)
# plot(point121T, add=T, pch=19, col='black', cex=2)
# 
# r7<- Cl
# stepsize = (r7@extent@ymax - r7@extent@ymin) / r7@nrows
# yvals = seq(r7@extent@ymax - stepsize / 2, r7@extent@ymin, -stepsize)
# xvals7 = rowMeans(as.matrix(r7), na.rm=TRUE)
# 
# plot(xvals7, yvals, type='l')
# point121T@coords[1,2]
# abline(h=point121T@coords[1,2])
# 
# 
# 
# 
# 
# 
# plot(NEIS)
# plot(point135T, add=T, pch=19, col='black', cex=2)
# 
# r8<- NEIS
# stepsize = (r8@extent@ymax - r8@extent@ymin) / r8@nrows
# yvals = seq(r8@extent@ymax - stepsize / 2, r8@extent@ymin, -stepsize)
# xvals8 = rowMeans(as.matrix(r8), na.rm=TRUE)
# 
# plot(xvals8, yvals, type='l')
# point135T@coords[1,2]
# abline(h=point135T@coords[1,2])
# 
# 
# 
# plot(WIS)
# plot(point136T, add=T, pch=19, col='black', cex=2)
# 
# r9<- WIS
# stepsize = (r9@extent@ymax - r9@extent@ymin) / r9@nrows
# yvals = seq(r9@extent@ymax - stepsize / 2, r9@extent@ymin, -stepsize)
# xvals9 = rowMeans(as.matrix(r9), na.rm=TRUE)
# 
# plot(xvals9, yvals, type='l')
# point136T@coords[1,2]
# abline(h=point136T@coords[1,2])
# 
# 
# 
# 
# plot(EIS)
# plot(point126T, add=T, pch=19, col='black', cex=2)
# 
# r10<- EIS
# stepsize = (r10@extent@ymax - r10@extent@ymin) / r10@nrows
# yvals = seq(r10@extent@ymax - stepsize / 2, r10@extent@ymin, -stepsize)
# xvals10 = rowMeans(as.matrix(r10), na.rm=TRUE)
# 
# plot(xvals10, yvals, type='l')
# point126T@coords[1,2]
# abline(h=point126T@coords[1,2])
# 
# 
# mat<- matrix(c(xvals1, xvals2, xvals3, xvals4, xvals5, xvals6,xvals7, xvals8, xvals9,  xvals10, xvals10, xvals9, xvals8, xvals7, xvals6, xvals5,xvals4, xvals3, xvals2,  xvals1), nrow = nrow(r1), ncol = 10, byrow = FALSE, dimnames = list(c(1:122), c("NNM", "Off", 'NM', 'Woff', 'SM', 'Jur', 'Cl', 'NEIS', 'WIS', 'EIS')
#                                ))

mat[1:6,1:6]
image(t(mat), xaxt='n', yaxt='n',col=blues(1000))
axis(3, at=c( 0.0, 0.11, 0.22, 0.33, 0.44, 0.55, 0.66, 0.77, 0.88, 1), labels=c("NNM", "Off", 'NM', 'Woff', 'SM', 'Jur', 'Cl', 'NEIS', 'WIS', 'EIS'))
#axis(2, at=rev(c( 0.0, 0.11, 0.22, 0.33, 0.44, 0.55, 0.66, 0.77, 0.88, 1)), labels=c("NNM", "Off", 'NM', 'Woff', 'SM', 'Jur', 'Cl', 'NEIS', 'WIS', 'EIS'))
axis(2, at = seq(0,1, length.out= 17), label = F,pos = -0.06, tck = -0.015)

axis(2, at = seq(0,1, length.out= 9), labels = parse(text = paste(c(52:60), "*degree ~ N", sep = "")),tick = F, pos = -0.06, las = 1, cex.axis=1.5, hadj=1)

```

#circle area plots
```{r}
# sea.spdf<- readOGR(dsn="E:/R_script/basic_maps", layer="basic_sea")
# depth.sldf<- readOGR(dsn="E:/R_script/basic_maps", layer="depth_area")
# 
# land.tmp<- readOGR(dsn="E:/R_script/basic_maps", layer="Britain_Proj_Dist")
# land.tmp <- spTransform(land.tmp, CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0")) ### re project land
# land.spdf <- crop(land.tmp, full.ext) ## crop land down to the correct extent
# 
# 
# #### initially produce a map of everywhere and all time points
# ## bind coords into sigle object
# coords.tmp<- cbind(int$Mid_long, int$Mid_lat)
# ## create spdf object
# samples.spdf<- SpatialPointsDataFrame(coords.tmp, data = data.frame(int),
#                                   proj4string = CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0"))




seaT<- spTransform(sea.spdf, CRS(mrc))
twohunT<- spTransform(twohun.sldf, CRS(mrc))
onehunT<- spTransform(onehun.sldf, CRS(mrc))

### plot land and sea####

plot(landT, add = F, col = 'cornsilk', border = 'cornsilk')
plot(seaT, add=T, col = 'cornflower blue')
## axes - note this needs changed on mac for degree symbol
#axis(1, at = c(-1:-10),labels = parse(text = paste(c(1:10), "*degree~W", sep = "")), cex.axis = 1.5, pos = 52, tck = -0.015,padj=0.2)
#axis(2, at = seq(52,60, by= 0.5), label = F,pos = -10, tck = -0.015)
#axis(2, at = c(52:60), labels = parse(text = paste(c(52:60), "*degree ~ N", sep = "")),tick = F, pos = -10, las = 1, cex.axis=1.5, hadj=1)
#axis(3, labels = F, pos = 59.7, at = c(-1:-10), lwd.ticks=0)
#axis(4, labels = F, pos = -1, at = seq(52,59.5, by= 0.5), lwd.ticks=0)

## bathemetry
plot(onehunT,add=T, col = ' lightskyblue3')
plot(twohunT,add =T, col = 'lightskyblue4')
#rect(-9.8, 55.7, -8.8, 56.3, col = 'cornflowerblue', border = NA )
#rect(-9.6, 54.4, -8.8, 55.08, col = 'cornflowerblue', border = NA)
#text(-9.2,56, labels= '200m', col ='lightskyblue4', cex = 0.8, srt = 81)
#text(-9.35,54.8, labels= '100m', col ='lightskyblue3', cex = 0.8, srt = 65)

## country names
#text(-3.6, 57, labels = 'Scotland', srt=40)
#text(-1.8, 54, labels = 'England', srt=50)
#text(-6.5, 54.7, labels = 'N. Ireland', srt=-54)
#text(-7.5, 53, labels = 'Eire')
#text(-3.4, 53, labels = 'Wales')
samplesT<- spTransform(samples.spdf, CRS(mrc))
points(samplesT, pch=19, cex=3)

plot(c.NNM, add=T)
plot(c.Off, add=T)
plot(c.NM, add=T)
plot(c.Woff, add=T)
plot(c.SM, add=T)
plot(c.Jur, add=T)
plot(c.Cl, add=T)
plot(c.NEIS, add=T)
plot(c.WIS, add=T)
plot(c.EIS, add=T)







str(int$region)
### add sampling points

text(samples.spdf, labels=int$Haul_id)
#plot(samples.spdf, add =T, cex = 2.5, pch= c(15,17,19,2,3)[as.numeric(int$region)], lwd=2)

#legend(-2.75, 53.1,legend =levels(int$region),
  #     pch= c(15,17,19,2,3), cex = 1, box.col = 'black', bg = 'cornsilk', horiz = F)



north.arrow(xb=-9.5, yb=59, len=0.08, lab="N")

table(int$Haul_id)



```


#Plots
```{r}


temp<- c('#FFFFFF',brewer.pal(9,'YlOrRd')[2:9])
temp
temp<- colorRampPalette(temp)

## get data points for haul locations
# Clyde<- SpatialPoints(cbind(chemC$long, chemC$lat), CRS(WGS84))
# ClydeT<- spTransform(Clyde, CRS(mrc))
# Ins<- SpatialPoints(cbind(chemI$long, chemI$lat), CRS(WGS84))
# InsT<- spTransform(Ins, CRS(mrc))
# Offs<-SpatialPoints(cbind(chemO$long, chemO$lat), CRS(WGS84))
# OffsT<- spTransform(Offs, CRS(mrc))
# EIS<-SpatialPoints(cbind(chemE$long, chemE$lat), CRS(WGS84))
# EIST<- spTransform(EIS, CRS(mrc))
# WIS<-SpatialPoints(cbind(chemW$long, chemW$lat), CRS(WGS84))
# WIST<- spTransform(WIS, CRS(mrc))

######## plot environmental data
L <- parse(text = paste(c(8,6,4), "*degree ~W", sep = "")) # longitudes
LN<- parse(text = paste(c(52:60), "*degree ~N", sep = "")) #lats


#display.brewer.all()
# blues<- colorRampPalette(brewer.pal(9,'Blues'), alpha=T)
# greens<- colorRampPalette(brewer.pal(9,'Greens'), alpha=T)
# reds<- colorRampPalette(brewer.pal(9,'Reds'), alpha=T)
# 
# 
# blues<- addalpha(blues(100), 1)
# greens<- addalpha(greens(100), 1)
# reds<- addalpha(reds(100), 1)


pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/NNoff.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)


#### N N offshore ####
#par(mar = c(5,6,2,2))   #7265958
image(NNM, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(NNM, col = temp(1000), zlim= c(0,1), add=T)


plot(landT, add =T, col = 'grey70')
#plot(point127T, add=T, pch=18, col='black', cex=4.5)
plot(point127T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point127T, add=T, pch=20, col='black', cex=3)


axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.2)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1, cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)

dev.off()   
#this is nice but the black doent work
#colfunc <- colorRampPalette(c("black", "midnightblue", "skyblue"))
#Legend

pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/legend.pdf",width=8.2, height=11.6)



plot(orig127, horizontal=T,   zlim=c(0,20), smallplot= c(0.2,0.8, 0.6,0.62), col = temp(1000),legend.only=TRUE,  axis.args = list(cex.axis = 2, at = c(0, 5,10,15,20), labels =c("0.0","0.25","0.5","0.75","1.0") ))

dev.off()

# Offshore ####
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/off.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig124, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig124, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point124T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point124T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)

dev.off()



#N Minch
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/Nminch.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig117, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig117, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point117T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point117T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


dev.off()


#W Off
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/Woff.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig118, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig118, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point118T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point118T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


dev.off()



#S Minch
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/Sminch.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig123, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig123, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point123T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point123T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


dev.off()


#Jura
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/Jura.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig122, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig122, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point122T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point122T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


dev.off()



#Clyde
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/Clyde.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig121, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig121, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point121T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point121T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


dev.off()



#NEIS
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/NEIS.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig135, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig135, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point135T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point135T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


dev.off()




#WIS
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/WIS.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig136, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig136, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point136T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point136T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


dev.off()





#SEIS
#par(mar = c(5,6,2,2))   #7265958
pdf(file="C:/Users/neilm/Desktop/Summer_19_work/Otolith_chem_paper/final figs/SEIS.pdf",width=8.2, height=11.6)

par(mar=c(3,5,1,0)+0.1)

image(orig126, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
image(orig126, col = temp(1000), zlim= c(0,20), add=T)
plot(landT, add =T, col = 'grey70')
plot(point126T, add=T, pch=1, col='black', cex=4.5, lwd=3)
plot(point126T, add=T, pch=20, col='black', cex=3)

axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
abline(h=-1057535.2)
axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


dev.off()

#Legend
#plot(origIn, horizontal=T,   zlim=c(0,nrow(chemI)), smallplot= c(0.2,0.8,0.6,0.62), col = greens,legend.only=TRUE,  axis.args = list(cex.axis = 2))

# 
# #Offshore
# par(mar = c(5,6,2,2))   #7265958
# image(origCl, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
# image(origOff, col = greens, zlim= c(0:1), add=T)
# plot(landT, add =T, col = 'bisque')
# plot(OffsT, add=T, pch=19, col='black', cex=4.5)
# 
# axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
# abline(h=-1057535.2)
# axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
# axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)


#EIS
# par(mar = c(5,6,2,2))   #7265958
# image(origCl, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
# image(origEIS, col = greens, zlim= c(0,nrow(chemE)), add=T)
# plot(landT, add =T, col = 'bisque')
# plot(EIST, add=T, pch=19, col='black', cex=4.5)
# 
# axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
# abline(h=-1057535.2)
# axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
# axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)
# 
# #Legend
# plot(origEIS, horizontal=T,   zlim=c(0,nrow(chemE)), smallplot= c(0.2,0.8,0.6,0.62), col = greens,legend.only=TRUE,  axis.args = list(cex.axis = 2))
# 
# #WIS
# par(mar = c(5,6,2,2))   #7265958
# image(origCl, col = 'white', xaxt='n', yaxt='n',xlim=c(-1057535.2,-278298.7), ylim= c(6800125,8399738), xlab=NA, ylab=NA) ###use image to keep plot in same 'window' for plotting - plot() extends plotting area
# image(origWIS, col = greens, zlim= c(0,nrow(chemW)), add=T)
# plot(landT, add =T, col = 'bisque')
# plot(WIST, add=T, pch=19, col='black', cex=4.5)
# 
# axis(1, at=c( -890555.9, -667916.9, -445278.0), L, lwd.ticks=1, cex.axis=2, padj=0.8)
# abline(h=-1057535.2)
# axis(2, at=c(6800125, 6982998, 7170156, 7361866, 7558416, 7760119, 7967318, 8180387, 8399738), labels=LN, lwd.ticks=1, pos=-1057535.2, las=1,cex.axis=2)
# axis(4, at=c(6800125,8399738), labels=NA, lwd.ticks=0, pos=-278298.7)
# 
# #Legend
# plot(origWIS, horizontal=T,   zlim=c(0,nrow(chemW)), smallplot= c(0.2,0.8, 0.6,0.62), col = greens,legend.only=TRUE,  axis.args = list(cex.axis = 2))

```

#End


